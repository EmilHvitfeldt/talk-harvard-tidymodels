---
format:
  revealjs: 
    theme: [default, styles.scss]
    width: 1280
    height: 720
    include-after-body: 
      - "all-the-js-code.html"
echo: true
code-line-numbers: false
cache: true
---

# {.center}

::: {.title}
<b>
Whatâ€™s <span>New</span> in <span>Tidy</span>model<span>s</span>
</b>
:::

::: footer
Emil Hvitfeldt

R User Group at the Harvard Data Science Initiative
:::

## What is tidymodels?

![](images/tidymodels.png)

## Data

[The Movies Dataset](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset) data set from [Kaggle](https://www.kaggle.com/)

Filtered to only include Horror movies

```{r}
#| echo: false
library(tidymodels)
library(censored)
library(tidyclust)

horror_movies <- readRDS("~/Desktop/talk-harvard-tidymodels/horror_movies.rds") |>
  mutate(time = if_else(target, time, time / 10))
```

```{r}
horror_movies |>
  relocate(title, id, runtime, genres) |>
  glimpse()
```

Heavily modified (turns out it is hard to force a themed example)

##

::: {.title}
<b>
<span>Val</span>ida<span>tion</span> splits
</b>
:::

## Validation splits

We can use `initial_validation_split()` to create a 3-way split of our data

```{r}
#| echo: true
set.seed(1234)
horror_split <- horror_movies |>
  mutate(surv = Surv(time, target)) |>
  select(-time, -target) |>
  initial_validation_split()

horror_split
```

this can then be turned into a `rset` object for tuning purposes

```{r}
#| echo: true
horror_set <- validation_set(horror_split)
horror_set
```

::: footer
Added in [rsample 1.2.0](https://rsample.tidymodels.org/news/index.html#rsample-120) and [tune 1.1.2](https://tune.tidymodels.org/news/index.html#tune-112) on 2023-08-23
:::

## Validation splits

We can also use `training()`, `testing()` and `validation()` functions as we know them

```{r}
#| echo: true
horror_train <- training(horror_split)
horror_train
```

::: footer
Added in [rsample 1.2.0](https://rsample.tidymodels.org/news/index.html#rsample-120) and [tune 1.1.2 ](https://tune.tidymodels.org/news/index.html#tune-112) on 2023-08-23
:::

#

::: {.title}
<b>
Multi <span>Dummy</span> Variables
</b>
:::

## Multi Dummy Variables

both the `genres` and `production_countries` variable is formatted as comma-separated lists:

```{r}
horror_train$genres[1:10]
```

This gives high cardinality

```{r}
#| echo: true
horror_train$genres |> unique() |> length()
```

despite low number of genres

```{r}
#| echo: true
horror_train$genres |> strsplit(", ") |> unlist() |> unique() |> length()
```

## Creating dummies

With `step_dummy(genres)`

```{r}
recipe(~ genres, data = horror_train) |>
  step_dummy(genres) |>
  prep() |>
  bake(new_data = NULL)
```

## Creating fancy dummies

With `step_dummy_extract(genres, sep = ", ")`

```{r}
recipe(~ genres, data = horror_train) |>
  step_dummy_extract(genres, sep = ", ") |>
  prep() |>
  bake(new_data = NULL)
```

::: footer
Added in [recipes 0.2.0](https://recipes.tidymodels.org/news/index.html#recipes-020s) in 2022-02-18
:::

## Creating fancy dummies

With `threshold = 0.1`

```{r}
recipe(~ genres, data = horror_train) |>
  step_dummy_extract(genres, sep = ", ", threshold = 0.1) |>
  prep() |>
  bake(new_data = NULL)
```

::: footer
Added in [recipes 0.2.0](https://recipes.tidymodels.org/news/index.html#recipes-020s) in 2022-02-18
:::

## Dealing with Dates

We use `step_date()` to deal with `release_date` variable

with the arguments `features = c("dow", "month")`, `label = FALSE`, and `keep_original_cols = FALSE`

```{r}
recipe(~ release_date, data = horror_train) |>
  step_date(all_date_predictors(), features = c("dow", "month"), label = FALSE, keep_original_cols = FALSE) |>
  prep() |>
  bake(new_data = NULL)
```

## New recipes selectors

In addition to `all_predictors()` and `all_outcomes()`

::: columns
::: {.column width="50%"}
- [all_numeric()]{.green .code}
    - [all_double()]{.green .code}
    - [all_integer()]{.green .code}
- [all_logical()]{.pink .code}
- [all_date()]{.blue}
- [all_datetime()]{.red}
:::

::: {.column width="50%"}
- [all_nominal()]{.purple .code}
    - [all_string()]{.purple .code}
    - [all_factor()]{.purple .code}
    - [all_unordered()]{.purple .code}
    - [all_ordered()]{.purple .code}
:::
:::

all have `*_predictors()` variants


::: footer
Added in [recipes 1.0.3](https://recipes.tidymodels.org/news/index.html#recipes-103) in 2022-11-09
:::

## Final recipe

Taking everything together, we can create a recipe we will use now

```{r}
#| echo: true
surv_rec <- recipe(surv ~ ., data = horror_train) |>
  update_role(id, title, new_role = "ID") |>
  step_dummy_extract(genres, spoken_languages, sep = ", ", threshold = 0.1) |>
  step_dummy_extract(production_countries, sep = ", ", threshold = 0.05) |>
  step_impute_median(budget) |>
  step_date(all_date_predictors(), 
            features = c("dow", "month"), label = FALSE, 
            keep_original_cols = FALSE)
```

## Sneak peak at data

```{r}
surv_rec |>
  prep() |>
  bake(new_data = NULL) |>
  glimpse()
```

#

::: {.title}
<b>
<span>Survival</span> analysis
</b>
:::

## {.center}

problem: you are working with [time-to-event]{.green} data and you wanna do it [right]{.orange}!

<br>

For the horror movie data set, the event is "100 ratings", and the time is calculated in weeks

<br>

Is this the best example? No, but it is ðŸŽƒseasonalðŸŽƒ

## What do we have

- multiple different models in [censored](https://censored.tidymodels.org/)
- a number of performance metrics in [yardstick](https://yardstick.tidymodels.org/)
- support for tuning multiple models with [tune](https://tune.tidymodels.org/)

For the best experiance, install dev versions

```r
# pak::pak(c("tidymodels/censored", "tidymodels/parsnip", "tidymodels/tune"))
```

We are very close! and would love any last minute feedback

## specifying the models

if you know how to use [parsnip](https://parsnip.tidymodels.org/), then you know how to use survival models

All the engines are provided in [censored](https://censored.tidymodels.org/)

Notice the new mode `"censored regression"`

```{r}
#| echo: true
sr_spec <- 
  survival_reg(dist = "weibull") %>%
  set_engine("survival") %>% 
  set_mode("censored regression") 

sr_spec
```

## Types of models

We used a Parametric survival regression model, but there are also

- Decision trees
- Bagged trees
- Boosted trees
- Random forests
- Proportional hazards regression

## Works with workflows

These types of models behave basically the same as other models

the only difference is the outcome needs to be a `Surv()` object

```{r}
#| echo: true
surv_wflow <- workflow() |>
  add_recipe(surv_rec) |>
  add_model(sr_spec)

surv_wflow_fit <- fit(surv_wflow, horror_train)
surv_wflow_fit
```

## Prediction

In the time-to-event setting, there are many things we could try to predict. In tidymodels we believe we got it covered

These are selected by setting `type =` and sometimes specifying `eval_times`

## Prediction - time

for `type = "time"` we get time to event prediction (The default)

```{r}
surv_wflow_fit |>
  predict(horror_train, type = "time") 
```

## Prediction - linear prediction

for `type = "linear_pred"` we get the linear prediction

```{r}
surv_wflow_fit |>
  predict(horror_train, type = "linear_pred") 
```

## Prediction - quantile

for `type = "quantile"` we get the quantiles of the event time distribution

You can set `quantile` to something other than the default `(1:9)/10`

```{r}
surv_wflow_fit |>
  predict(horror_train, type = "quantile") 
```

## Prediction - quantile

for `type = "quantile"` we get the quantiles of the event time distribution

You can set `quantile` to something other than the default `(1:9)/10`

```{r}
surv_wflow_fit |>
  predict(horror_train, type = "quantile") |>
  slice(1:2) |>
  pull(.pred)
```

## Prediction - survival

for `type = "survival"` we get the survival probability 

```{r}
surv_wflow_fit |>
  predict(horror_train, 
          type = "survival", 
          eval_time = c(1, 10, 20, 30)) 
```

## Prediction - survival

for `type = "survival"` we get the survival probability (The default)

```{r}
surv_wflow_fit |>
  predict(horror_train, 
          type = "survival", 
          eval_time = c(1, 100, 200, 300)) |>
  slice(1:2) |>
  pull(.pred)
```

## Prediction - hazard

for `type = "hazard"` we get the hazard estimate

```{r}
surv_wflow_fit |>
  predict(horror_train, 
          type = "hazard", 
          eval_time = c(1, 10, 20, 30)) 
```

## Prediction - hazard

for `type = "hazard"` we get the hazard estimate

```{r}
surv_wflow_fit |>
  predict(horror_train, 
          type = "hazard", 
          eval_time = c(1, 100, 200, 300)) |>
  slice(1:2) |>
  pull(.pred)
```

## Performance metrics

There are a couple of performance metrics that work specifically with survival data. 

- [Concordance index for right-censored data](https://yardstick.tidymodels.org/reference/concordance_survival.html)
- [Time-Dependent Brier score for right censored data](https://yardstick.tidymodels.org/reference/brier_survival.html)
- [Integrated Brier score for right censored data](https://yardstick.tidymodels.org/reference/brier_survival_integrated.html)
- [Time-Dependent ROC surve for Censored Data](https://yardstick.tidymodels.org/reference/roc_curve_survival.html)
- [Time-Dependent ROC AUC for Censored Data](https://yardstick.tidymodels.org/reference/roc_auc_survival.html)

::: footer
[Dynamic Performance Metrics for Event Time Data](https://www.tidymodels.org/learn/statistics/survival-metrics/)
:::

## Performance metrics

Using `augment()` to `predict()` + `bind_cols()`

```{r}
preds <- surv_wflow_fit |>
  augment(horror_train, eval_time = c(1, 100, 200, 300))

glimpse(preds)
```

::: footer
[Dynamic Performance Metrics for Event Time Data](https://www.tidymodels.org/learn/statistics/survival-metrics/)
:::

## Performance metrics

You need a lot of information for some of these metrics, `.censoring_weights_graf()` can sometimes help

```{r}
preds <- surv_wflow_fit |>
  augment(horror_train, eval_time = c(1, 100, 200, 300))

# hopefully better interface soon
.censoring_weights_graf(surv_wflow_fit, preds) |>
  brier_survival(truth = surv, .pred)
```

::: footer
[Dynamic Performance Metrics for Event Time Data](https://www.tidymodels.org/learn/statistics/survival-metrics/)
:::

## Fitting many models

```{r}
tune_res <- fit_resamples(surv_wflow, horror_set, eval_time = c(1, 10, 30, 50)) 
tune_res

tune_res |>
  collect_metrics()
```

#

::: {.title}
<b>
Cluste<span>ring</span>
</b>
:::

## What is clustering?

you have some data, with no clear outcome, and you want to see if you can partition the data

## What we have

- some models
- some metrics
- extraction
- tuning

All in [tidyclust](https://tidyclust.tidymodels.org/)

## clustering recipe

Loan from the previous recipe, now with no outcome and normalization

```{r}
#| echo: true
clust_rec <- recipe(~ ., data = horror_train) |>
  update_role(id, title, surv, new_role = "ID") |>
  step_dummy_extract(genres, spoken_languages, sep = ", ", threshold = 0.1) |>
  step_dummy_extract(production_countries, sep = ", ", threshold = 0.05) |>
  step_impute_median(budget) |>
  step_date(all_date_predictors(), 
            features = c("dow", "month"), label = FALSE, 
            keep_original_cols = FALSE) |>
  step_normalize(all_numeric_predictors())
```

## Peak the data

```{r}
clust_rec |>
  prep() |>
  bake(new_data = NULL) |>
  glimpse()
```

## Specifying models and fitting

tidyclust is different from parsnip, but is used in almost the same way

```{r}
kmeans_spec <- k_means(num_clusters = 4) |>
  set_engine("stats") |>
  set_mode("partition")

kmeans_wflow <- workflow(clust_rec, kmeans_spec)

kmeans_fit <- fit(kmeans_wflow, data = horror_train)
```

## Available models

- K-Means
  - K-Means
  - K-Modes
  - K-Prototypes
- Hierarchical (Agglomerative) Clustering

More to come next release

::: footer
[cluster specifications](https://tidyclust.tidymodels.org/reference/index.html#specifications)
:::

## cluster assignment + clusters + prediction

```{r}
extract_cluster_assignment(kmeans_fit)
```

## cluster assignment + clusters + prediction

```{r}
extract_centroids(kmeans_fit)
```

## cluster assignment + clusters + prediction

```{r}
predict(kmeans_fit, new_data = horror_train)
```

## Looking at the clusters

```{r}
#| echo: false
clust_data <- clust_rec |>
  prep() |>
  bake(new_data = NULL, all_predictors())
  
set.seed(1234)
umap_data <- recipe(~., data = clust_data) |>
  embed::step_umap(all_predictors(), neighbors = 50, min_dist = 0.25) |>
  prep() |>
  bake(new_data = NULL)

bind_cols(
  extract_cluster_assignment(kmeans_fit),
  umap_data
) |>
  ggplot(aes(UMAP1, UMAP2, color = .cluster)) +
  geom_point(alpha = 0.3) +
  theme_minimal() +
  scale_color_viridis_d() +
  guides(color = "none")
```

## Cluster aware metrics

Metrics are available to, that uses information about centriods

```{r}
my_metrics <- cluster_metric_set(sse_ratio, sse_within_total)

my_metrics(kmeans_fit)
```

::: footer
[Model based performance metrics](https://tidyclust.tidymodels.org/reference/index.html#model-based-performance-metrics)
:::

## You can do tuning as well!

By setting `tune()` in our cluster spec, we can find the "optimal" value, using `tune_cluster()` where we would use `tune_grid()`

::: footer
[Introductory talk for tidyclust](https://emilhvitfeldt.com/talk/2022-07-27-rstudioconf-tidyclust/)
:::

#

::: {.title}
<b>
Conformal inference
</b>
:::

## how to make prediction intervals with no parameteric asssumptions

[Max Kuhn - Conformal Inference with Tidymodels](https://reg.conf.posit.co/flow/posit/positconf23/attendee-portal/page/sessioncatalog/session/1685040648021001GQc9)

[Talk material](https://github.com/topepo/posit-2023-conformal)

Recording up "soon" on [Youtube](https://www.youtube.com/@PositPBC)

using [probably](https://probably.tidymodels.org/)

[tidymodels.org article](https://www.tidymodels.org/learn/models/conformal-regression/index.html)

#

::: {.title}
<b>
<span>Cali</span>bration
</b>
:::

## Post-processing tool

There are essentially three different parts to a predictive model:

- the pre-processing stage
- model fitting
- post-processing

Does your model always predict between 40% and 60%? then you might need calibration!

also using [probably](https://probably.tidymodels.org/)

[tidymodels.org article](https://www.tidymodels.org/learn/models/calibration/index.html)

## Causal inference

we want more eyes!

[Link here if interested](https://github.com/tidymodels/tune/issues/652)

## Coming up soon

- fairness metrics
- cli errors (this year ðŸ¤ž)

## where to look

::: columns
::: {.column width="60%"}

[tidyverse blog](https://www.tidyverse.org/blog/)

[tidymodels website](https://www.tidymodels.org/)

:::

::: {.column width="40%"}

[{{< fa brands github >}} EmilHvitfeldt](https://github.com/emilhvitfeldt)

<br>

[{{< fa brands linkedin >}} EmilHvitfeldt](https://www.linkedin.com/in/emilhvitfeldt/)

<br>

[{{< fa brands mastodon >}} EmilHvitfeldt](https://fosstodon.org/@emilhvitfeldt)

<br>

[<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 192 192" fill="#FFC341" style="height:1em;"><path d="M141.54 88.988a66.667 66.667 0 0 0-2.518-1.143c-1.482-27.307-16.403-42.94-41.457-43.1h-.34c-14.986 0-27.449 6.396-35.12 18.035l13.78 9.452c5.73-8.694 14.723-10.548 21.347-10.548h.23c8.248.054 14.473 2.452 18.502 7.13 2.932 3.405 4.893 8.11 5.864 14.05-7.314-1.244-15.224-1.626-23.68-1.141-23.82 1.372-39.134 15.265-38.105 34.569.522 9.792 5.4 18.216 13.735 23.719 7.047 4.652 16.124 6.927 25.557 6.412 12.458-.683 22.231-5.436 29.05-14.127 5.177-6.6 8.452-15.153 9.898-25.93 5.937 3.583 10.337 8.298 12.767 13.966 4.132 9.635 4.373 25.468-8.546 38.376-11.319 11.308-24.925 16.2-45.488 16.35-22.809-.168-40.06-7.483-51.275-21.741C35.238 139.966 29.811 120.682 29.608 96c.203-24.682 5.63-43.966 16.133-57.317C56.957 24.425 74.207 17.11 97.016 16.94c22.975.17 40.526 7.52 52.171 21.848 5.71 7.025 10.015 15.86 12.853 26.162l16.147-4.308c-3.44-12.68-8.853-23.606-16.219-32.668C147.04 9.608 125.205.195 97.072 0h-.113C68.884.195 47.294 9.643 32.79 28.08 19.884 44.487 13.226 67.316 13.002 95.933v.135c.224 28.616 6.882 51.446 19.788 67.854C47.294 182.359 68.883 191.807 96.96 192h.112c24.96-.173 42.554-6.708 57.048-21.19 18.963-18.944 18.392-42.691 12.142-57.27-4.484-10.453-13.033-18.944-24.723-24.552zm-43.096 40.519c-10.44.588-21.286-4.098-21.821-14.135-.396-7.442 5.296-15.746 22.462-16.735 1.966-.113 3.895-.169 5.79-.169 6.235 0 12.068.606 17.37 1.765-1.977 24.702-13.58 28.713-23.801 29.274z"/></svg> EmilHvitfeldt](https://www.threads.net/@emilhvitfeldt)

:::
:::
